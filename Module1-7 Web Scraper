Finding & Getting Data - Web Scraper
このビデオでは、Google ChromeのWeb Scraperというとても便利な拡張機能を紹介します。
Chrome　Webストアから検索してダウンロードしてください。こんな感じのページです。
Web Scraperを使用すると、Webサイトから情報をスクレイピングして、独自のデータセットを作成することができます。例えば、Billboard200のウェブページを見てみると、毎週のトップ曲がリストされています。
このデータセットを取得するにはコピー＆ペーストする必要がありますが、全てをコピー＆ペーストすることはできないので、（このままでは）全ての情報を手で入力するしかないのです。
テーブルではないので、importHTMLは機能しません。私たちの目標は、全ての情報をテーブルに取り込み、このようにすることです。
この情報をスクレイピングした時点でのアーティスト、順位、URL、さらにはスクレイピングした週までもが列に入っています。
これを実現するために必要なのは特定のパターンを見つけて情報を収集し、データセットにすることです。
Webページを見てみましょう。白いボックスが見えますよね。パターンを見つけて情報を集めるにはどうしたらいいのでしょうか。
このボックスは200個あって、必要な情報はこの中に納められています。曲の名前はここ、アーティスト名はここ、順位はここにあって、そうそう、アルバムの画像もここにあります。週の情報もここにありました。
ここでは、Web Scraperを使用してこれらの情報をすべて収集します。
まず、Webインスペクタメニューにアクセスします。任意の場所を右クリックし、「検証」を選ぶとタブ右端にWeb Scraperという新しいオプションが表示されます。
ここにある三つの点から"Dock to bottom"を選択すると画面下部にWeb scraperが展開されます。上部には三つの選択肢があり、これがsitemapです。
これはスクレイピングを開始するロボットとルーチンです。「新しいサイトマップの作成」または「新しいサイトマップのインポート」というオプションがあります。
「サイトマップの作成」を選択し、Billboard200という名前を付けて、URLを入力します。
次に、新しいSelectorを追加します。Selectorは、Webページ上の要素を識別できる情報です。
ここをクリックして青いボタンをクリックするだけで、この白いボックスがどこにあるのかWeb Scraperに指示できます。そうですね。
Web Scraperに「Web Scraper、このページで200個のボックスを検索」と指示し、ボックスのどこに情報があるかを伝えスクレイピングできるようにします。
ここではこれをBOXと名付けましょう。これはWebページの要素なので、ここでのタイプはElementです。
「Select」をクリックすると、 「multiple」のボックスが表示されます。このチェックボックスをオンにします。
マウスを動かし始めると、Webページの要素がすべて表示され、どの部分を選択できるかが示されます。
右下の隅にカーソルを合わせるとボックス全体が緑になります。クリックすると赤になります。
次のボックスも同じようにして選択すると、Web scraperは他のボックスがどこにあるかを推測しようとします。
でも21個目で止まってしまいます。21個目のボックスも選択すると、ページ内の200個のボックスが全て識別されていますね。
ここに、これらのすべてのボックスを記述するselectorが入っていることがわかります。
気にしなくても、自動的にselectorは入力されます。 "Done selecting!" をクリックします。データをプレビューすることもできます。
まだスクレイピングしたデータはありませんが、要素のプレビューも可能です。ボックスの全てが選択されていることが確認できます。
保存してBOX（というselector）ができました。
ボックスをキャプチャするルーチンができましたが、次に200個のボックスの中の全ての情報をキャプチャするルーチンが必要です。
マウスをここに置くとボックスが灰色で強調表示されます。ボックスをクリックするとここで選択した一般的なボックスが表示されます。
Web Scraperに「ボックスの場所は教えたから、次はそれぞれのボックスの中の情報をキャプチャしてデータセットを作るように」と指示します。
それでは、曲名とアーティスト名、順位とアルバム画像のURLを取得します。"Add new selector"はBOXの中で行うことに注意してください。
新しいselectorを選択し、これを「song」と名付けます。「選択」をクリックし、曲名を選択します。
曲名が識別されたら、"Done selecting!"をクリックします。データをプレビューすると、全ての曲名がここに入っているので問題ありません。
selectorを保存します。新しいものを追加します。青のボタンをクリック。アーティスト名です。これはテキストなのでtypeはテキストを選びます。
selectorは「a」です。"Done selecting!" 。ここにはキャプチャされた全てのアーティスト名が表示されます。「保存する」をクリックします。
次は順位です。これもテキストです。"Select"をクリックし、順位をクリックします。そしてまた"Done selecting!"。ここで疑問に思われるかもしれませんが、「multiple」をオンにするとどうなるでしょう。
そうですね。先ほどは複数のボックスをキャプチャするために使いました。ここでは順位は黄色のボックスの中に一つしかありません。
複数のエレメントを選択する場合のみmultipleを選択します。この場合は順位も曲名もアーティスト名も一つしかないので、その必要はありません。さて、またselectorを保存します。
次はアルバム画像です。これはイメージなのでselector名も「image」としましょう。アルバム画像を選択し、"Done selecting!"をクリックしてから保存します。
 "_root"に戻って（「BOX」の）データをプレビューすると、必要なものがほぼ全てそろっているのが分かります。
曲名、アーティスト名、順位と画像のURLを手に入れました。しかしもう一つ、日付が必要だと思いませんか？日付はこのトップのところにあります。
次に各列に日付をつけましょう。
今はBOXの中にいるので"_root" に戻りましょう。そして新たに日付のselectorを作ります。
これもテキストのselectorです。ハイライト表示された部分を選んで "Done selecting!"
しかし、余計な情報も含まれています。必要なのは "August 31st"と2019だけです。どうやって抽出すればいいのでしょうか？
ここで正規表現を使いますが、詳細には触れません。「正規表現とは」とか優れたチュートリアル、よくできたクラスをぜひGoogleで検索してみてください。
特にプログラミングでは非常に強力な概念です。ありがたいことにWeb Scraperには"Regex"という正規表現を適用するフィールドがあります。
ここでは、日付だけを抽出するためのパターンを見つけたいと思います。"August 31st, 2019" といったような数字とコンマから構成されるテキストを抽出するようにします。
では、このオンラインの正規表現テスターを見てみましょう。8月31日の週とその前後の週、日付検索のストリングがあります。正規表現には三つの要素があります。7
最初は "\w+"で、バックスラッシュはトークンのようなものです。ｗは任意の文字で、a, b, c, dでも任意の数字でもかまいません。
どんな任意の文字でも入力でき、それに続く「＋」はスペースに達するまでどんな文字数でも許容することを示しています。
ただ、これは単なるスペースではなく、数字を意味する「\d」の前にあるスペースです。
つまり、任意の文字数の文字と、任意の数の前にスペースがあり、その後にコンマ、スペース、4桁の数字がある単語、これがこの正規表現の意味するところです。
Web scraperの正規表現のフィールド（Regex）にこれをコピーしてプレビューしてみると、「2019年８月31日」だけが表示されます。
これこそ私たちが望んでいた結果です。selectorを保存して終了します。ここに行きましょう。
ここでは、他のオプションを選択できます。セレクタ・グラフには"_root"と他の全てのselectorの関係が表示されます。これはページによってはかなり複雑になります。
メタデータ、サイト名またはURLを編集したり、スクレイピングすることもできます。スクレイピングしたデータを見たり、サイトマップをエクスポートしたりすることもできます。
これはJSONのようなもので紐づけたり、他のコンピュータで使用したり、友人に送信して別のコンピュータでスクレイピングルーチンを読み込んだりすることができます。
サイトを変更するために調整することも可能です。というわけでエクスポートする方法もあるのです。
また、読み込んだデータをCSVファイルとして書き出すこともできます。このオプションについて見てみましょう。
二つの選択肢があります。リクエスト間隔とはWebサイトにリクエストをする間の待機時間です。2000ミリ秒、つまり２秒は妥当なところです。
サイトに負荷をかけられるのはみんな嫌なので、過度に頻繁なリクエストは怪しまれるでしょう。サイトの管理者はあなたがサイトをダウンさせようとしていると考えるかもしれません。
このオプションは責任をもって管理してください。
もう一つは「遅延読み込み」です。これはweb scraperがページを読み込んでからデータをスクレイピングするまでの時間（をとること）です。
Webサイトに少しデータを読み込むための時間を与えて、スクレイピングするのですが、このとき情報をキャプチャする前に全てのデータが読み込まれていることを確かめてください。
最初は2000ミリ秒がいいでしょう。後で調整するかもしれません。
"start scraping"をクリックすると別ウィンドウが開きます。ページを読み込むのに２秒、リクエストを実行するのにさらに２秒かかります。
"refresh"を実行するとWeb scraperが追加するのと同じ情報が表示されます。まず初めにあるのはIDとURLです。そしてここにデータがあります。
曲名、アーティスト、順位、画像のURL、データが適用された日付がそろっている必要があります。
次に、ここをクリックして、CSV形式でエクスポートします。ここをクリックすると、CSVファイルがコンピュータにダウンロードされます。
これでCSVファイルを他の表計算アプリケーションにインポートして、分析、クリーニング、編集、またはデータセットの構築を開始できるようになりました。
