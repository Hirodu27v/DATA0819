Finding & Getting Data - Web Scraper
このビデオでは、Google ChromeのWeb Scraperというとても便利な拡張機能を使う方法をお見せします。
Chrome　Webストアから検索してダウンロードしてください。こんな感じのページです。
Web Scraperを使用すると、Webサイトから情報をスクレイピングして、独自のデータセットを作成することができます。例えば、Billboard200のウェブページを見てみると、毎週のトップ曲がリストされています。
このデータセットを取得するにはコピー＆ペーストする必要がありますが、全てをコピー＆ペーストすることはできないので、（このままでは）全ての情報を手で入力するしかないのです。
テーブルではないので、importHTMLは機能しません。私たちの目標は、全ての情報をテーブルに取り込み、このようにすることです。
この情報をスクレイピングした時点でのアーティスト、順位、URL、さらにはスクレイピングした週までもが列に入っています。
これを実現するために必要なのは特定のパターンを見つけて情報を収集し、データセットにすることです。
Webページを見てみましょう。白いボックスが見えますよね。パターンを見つけて情報を集めるにはどうしたらいいのでしょうか。
このボックスは200個あって、必要な情報はこの中に納められています。曲の名前はここ、アーティスト名はここ、順位はここにあって、そうそう、アルバムの画像もここにあります。週の情報もここにありました。
ここでは、Web Scraperを使用してこれらの情報をすべて収集します。
まず、Webインスペクタメニューにアクセスします。任意の場所を右クリックし、「検証」を選ぶとタブ右端にWeb Scraperという新しいオプションが表示されます。
ここにある三つの点から"Dock to bottom"を選択すると画面下部にWeb scraperが展開されます。上部には三つの選択肢があり、これがsitemapです。
これはスクレイピングを開始するロボットとルーチンです。「新しいサイトマップの作成」または「新しいサイトマップのインポート」というオプションがあります。
「サイトマップの作成」を選択し、Billboard200という名前を付けて、URLを入力します。

And now what we're going to do is to add a new selector. Selector are, you know, the
information that we can identify elements on the web page. So just click here and the blue
button and we want to tell Web Scraper where these white boxes are. Right. We want to
tell Web Scraper, "Web Scraper find 200 boxes on this page", and then after that we're
going to tell Web Scraper where the information is in all of these boxes so that it can
scrape it. But for now let's just call this "box" and it's an element on the web page. Right.
So the type here is "Element". We click here on "Select", and this is, this is going to be
multiple boxes. So we check this box here called multiple. And look when you start
hovering your mouse around you see that Web Scraper interact with the webpage showing
all of these elements and how clickable they are and how selectable they are.
So what we want to do is to find a spot here in the right lower corner that highlights in
green the full box at the top. We're going to click here and then it will become red, as soon
as we click. And then we're going to do the same for the next one and see that Web
Scraper tries to guess where all of the other boxes are. But then it stops at the 21st. So
we're gonna do that again for the 21st, and see that it identified all of the 200 boxes here
on the page. So this is where we want to be, right. We do this, and now notice that here,
there is selector that identifies that describes all of these boxes you don't have to worry
about this. Web Scraper automatically selects, identify the selector for you. Just click here
on "Done selecting!" And notice that this will come here. And then once you do that this is
the right signal so you can even preview this data. There's no data here that we're
scraping but it can also do an "Element preview" and you see that all of the the boxes are
selected. So we save this, and now we have the box.
Now we have the routine to capture
the box, but we need the routine to capture information in all of the 200 boxes.
So if you, if you hover your mouse here you see that it highlights in gray the box row here.
And if you click on the box, notice that we're now inside of this like generic boxes that we
selected here. We can come back to "_root" and we're going to come back there in a
second, but then we would click on the box and now we're in this box that we just
described and we want to tell Web Scraper, "look you know the location of the two
hundred boxes, but now I want you to capture information in every single box and do the
data set for me".
So, we're going to capture the name of the song, the name of the artist, the position, and
the URL of the image of the album, and let's do that. So, you "Add new selector",
remember inside here of the box. So we add a new selector, let's call this selector "song".
And then, we click here on "Select", and then we select the name of the song, it identifies
which selector it is and then click on "Done selecting!". We can do a data preview. So it
captures all of the name of the songs here so it looks fine, and then we save the selector.
Now we add a new one. Click on the blue button. This will be, this will be the artist.
This is also a text type because it's text here on the page. So we click here, this is the
artist. It's an "a" selector. We click on "Done selecting!" And then we can do a data
preview. Here it shows all the names of the artists that it captured on this page. We save
the selector. Now we're going to add the position. Now this is also a text element. So we
click here on "Select" and here's the position and then then "Done selecting!".
Now you might be asking, why not check the box multiple? Right. Because we check that
for the multiple boxes that we were capturing. Since we're capturing only one position
here, there are not multiple positions inside of this yellow box, we're not going to check the
multiple boxes. Only when there are occasions that you have to select multiple elements
that repeat in positions or in different cases, that you would select multiple. But in this case
is just one position, one name of song, one artist, so you don't check the multiple box.
All right. So we save the selector too. Now we're going to add the image, right. So this is
an image, and then we'll call this "image". We select here, the image of the album and
then "Done selecting!", and then we save. Now if we go back to "_root" and do "Data
preview" here, you will see that it already almost has everything that we need right.
We have the song, the artist, the position and then the URL of the song. But it's not quite
everything that we want, because we also want the date, right? And date is here at the top.
So what we want to do is to apply this date for every single row here. And to do that, we go
back to "_root" where we are. So we were in a box, now we go back to "_root" and then we
add a new selector for the date. And this is also a text selector, and then we're going to
highlight here all of this, and then we're gonna do "Done selecting!" But notice when you
preview this, it gets all of this information here that I don't want, I just want this "August
31st" and then 2019. So how do how do you can extract just this?
I'm not gonna go into details because I'm going to use regular expressions to do that. Feel
free to google regular expressions or great tutorials, great classes about regular
expression. They're very powerful, especially in programming. But thankfully the Web
Scraper also has a "Regex" or a regular expression field here that you can apply regular
expressions. So what we're gonna do is just I'm going to get all of this, and I want to find a
pattern to extract just this part here. This "August 31st, 2019" and I'm gonna do it in a way
that it extracts every time there is a text here that shows a word in a number comma, a
year it's going to extract just that.
So, I'm going to go here to this online regular expression tester, and see that I already
have here my string. So the week of August 31st, 2019 and then last week, next week,
current week, date search. What I'm doing here is using regular expression and I have
three elements. The first one is a "\w+" and it means this backslash is like a standard when
you want to use like in something of a token, that's called this "w" here. So "w" means any
word character. So any a, b, c, d, or any number. So it matches anything that happens
here and the "+" means any character to just one character, or an infinite number of
characters until it hits the space. But it's not only a space, it's a space that comes before
like a "\d" which means digits. Right. So it matches a digit equals to 0-9, and the plus
means matches between 1 and unlimited time, so any number of digits. So, it's a word with
any number of characters, a space that comes before any number of digits, and then there
is a comma, and then a space, and then four digits. That's what this means here.
And if you copy this here to the regular expression field in a web scraper and you do a
data preview you see that it extracts everything out and then it relieves only the August
31st, 2019. And that's exactly what we want. I'm gonna save this selector here and then
we're all done. So we're gonna go here. Here you can select other options, you can see
the selector graph where you see the "_root" and then all of the other selectors and then
the relation between them.
It can get fairly complicated depending on the complexity of the page. You can edit the
metadata, the name of the site, or the URL. You can also scrape. You can browse the
scrape data and you can even export this site map. So this is like a Jason that you can
string, that you can export and use in other computers, or send to a friend that will load the
same scraping routine in other computers. Or you can tweak it a bit to change the website.
So there is a way to export.
And then you can import as well and then you can export the data that you scraped as
"CSV". So we're gonna go ahead and scrape here on this option. So it gives you two, two
options. The "request interval" which is like the amount of time that you will wait until it
does a request to the website. And two ms, which is two seconds is good practice. So you
don't wanna be hammering the site with requests, so we might look suspicious. The
webmaster might think that you're trying to take this website, down so we don't want it
dead. You want to use this option responsibly.
And then there's the page load delay. The page load delay is the amount of time that web
scraper waits for the page to load and then to scrape the data. So you might want to give
the Web site some time to load the data and then to scrape it to finish, so that you can
guarantee that all elements load before you start capturing information with that.
So two and two seconds are good numbers to start but you might tweak it depending on
your case. So you click here on "start scraping", it opens a window. It waits two seconds to
load the page and then you wait two seconds to do the request, and then it scrapes the
data. And if you click here on "refresh" it will load all of the data that it just scraped, and
voila, we have here the same metadata that Web Scraper adds. This is the web scraper
I.D. for each one of the records, you have to start URL. Here we have the data that we
really want to scrape which song, the artist, the position, the image URL, and also the date
that was applied to every record here.
So now we can go ahead and click here and export this site at CSV. And when you click
here you're going to download the CSV file to your computer, and then you can import the
CSV file to any other spreadsheet application to start analyzing or cleaning, or editing, or
building your dataset. So that's it for Web Scraper. So, go to the Chrome Web Store,
download the extension and start scraping.
