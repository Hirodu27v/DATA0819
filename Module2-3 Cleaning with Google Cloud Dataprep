Preparing Data - Cleaning with Google Cloud Dataprep

乱雑なデータをクリーニングするいくつかの方法をご紹介します。サラ・コーエンの作った素晴らしい例を使いましょう。彼女はNYタイムズにいましたが、現在はアリゾナ大に籍を置いています。
それは2016年に開催されたコンピュータ支援報道の講義で発表されたものです。これは全てが含まれている優れた例です。
タイプミスや空白が含まれています。このデータはニューヨーク州の高齢者向け医療保険の長期管理ケア報告書から集められました。
ここにニューヨーク州の郡、次に総登録数、月と年の日付もありますが、さまざまな表記があって実に乱雑かつ質が低いものです。
それぞれのシートは月ごとに分けられていますが、彼女は全ての情報を一つのスプレッドシートにまとめました。
私たちはこのシートを加工して、このような見た目に仕上げたいと思います。
ある列にはプラン名、別の列には郡、登録数、月、年が表示されます。
各変数にはそれぞれの列が割り当てられています。合計値は必要ないので消去しています。
このビデオではGoogle data prepを使い、別のビデオではOpen refineで同じデータセットをクリーンアップする方法を説明します。
DataPrep by Trifactaは、Google Cloud Suiteの一部としてデータ分析やクリーニングを支援するツールです。
Dataprepは大量のデータセットを処理するのに適していますが、それだけでなく、データセットを素早く視覚化したり、クリーニングしたりするのに役立つアプリケーションでもあります。
何百万行ものデータセットにクリーニングルーチンを適用するときに大きな力を発揮します。しかし、サラの作った小さなデータセットにも使うことができます。
これは約6000行しかないので、それほど大きくありません。
さて、cloud.google.com/dataprepからコンソールに移動しましょう。アカウントを作成するよう促すメッセージに従ってアカウントを作ると、すぐこのようにアプリケーションをロードする画面に移動し、Dataprepを使い始めることができます。
ここで、データをインポートするためにファイルを選択します。このExcelファイルはフォーラムからダウンロードできるのでご心配なく。
ここをクリックすると起動し、アップロードが始まります。できましたか？自動的にExcelファイルであることを認識し、ファイルの中の特定のシートを読み込むことが表示されます。
"Import & Wrangle"をクリックするとすぐにファイルの処理を始めます。インターフェースはかなり直感的です。
このように複雑なデータセットの場合、ここにある多くのオプションを気にする必要はありませんが、気になりますよね。
上にある柱のようなものはカラムがないとか、値が一致しないということを通知してくれます。
クリックするだけで、列２に4000の欠損値があることが分かります。また、列４に一致しない値があることも見て取れます。さっきの完成形を見てみましょう。
プランの欄と、郡の欄と、それから登録、月、年の欄です。同じ順番でなくてもいいんです。まずすることはデータの抽出です。
年を取り出して、別の列を作りたいのです。ここでは2009を選択します。Dataprepは自動的に右側のメニューで、いくつかの操作を提案してくれます。
やりたいことは（年を表す）４桁の値を抽出することで、単に「2009」という数字を取り出すことではありません。
これで、抽出することができるようになりました。元の列は青、黄の列はこれから作成する列のプレビュー表示です。
2008、09、10、11、12、13、および14年の値が入ったカラムが作成されます。値の数も2008は12個、全体の18％などと表示されます。よければ"add"をクリックします。
新しい列を追加しました。後から全ての列の名前を変更するのでここでは気にしません。次は月を抽出したいのですが、年のときほど簡単にはいきません。
列２から抽出します。ここではカスタムテキストパターンのようにします。
月はいつも（ニューヨーク州を表す）NYSの後、４桁の数字の前にあります。４桁の数字を抽出したときのことを思い出してください。
ここには、４桁の数字（を表す正規表現）を入力します。数字、４桁ですね。できました。
周囲のスペースとカンマまで一緒に抽出してしまいました。後で対処しましょう。
月の列を作成しましょう。この空白を見てください。Dataprepが既に置換を提案しています。
「１月」の前後に空白があります。この空白を削除するには、これを選択してaddをクリックします。同じようにコンマも削除します。
これで、月と年の列ができました。１月がここにあり、スクロールダウンしていくと別の年の１月、さらにスクロールダウンするとまた別の年の１月が出てきます。
この間を2009で埋めます。2011が出てくるまでは2010で空白を埋めます。これはFill Downと呼ばれ、新しいステップを使用するだけでDataprepで自動的に実行できます。
 "new step"をクリックし、"window"と入力してください。そして"fill"と入れて、括弧の後に"column5"とタイプします。列５は現在加工している列です。
次に、ここにソースファイルの行番号であるソース番号を入力します。これを入力すると、ソースである青の列が、この黄色の列になっています。
こうして、２月という別の値が見つかるまで１月という値が空白を埋め、同じようにデータセットの最後まで値が自動的に入力されます。
年の列も月と同じようにnew stepからwindowに進み、fillを入力する手順を踏んで、addをクリックします。
ここに登録数、ここに月、年、そしてプランがあります。良くなってきましたが、まだやることがあります。
全ての列の名前を変更します。まず医療保険の列を変えましょう。この下向きの矢印をクリックして「名前変更」を選択し、"plan"と入力します。
そして、不要な列を削除します。この列も必要ありません。そして”country”、"enrollments","month"そしてこれが"year"とします。
では次に、上の（柱状の）図を見てみましょう。欠損値と、不一致の全ての値を検出できます。合計の削除から始めましょう。強調表示して、一致する全ての「合計」を削除するようDataprepに指示します。
医療保険の列にも同じくfill downをやってみたいと思いませんか？元の表では高齢者向け医療保険のグループが一緒の場合、空白になっています。

 So we need to make sure that those are
filled down with the names of the plans too. So we're gonna go ahead and do that. And if
you remember, this is a new step. "Window", the formula is "fill", and then we go to "plan"
which is the name of the column now, and then "sourcerownumber". And then it creates a
new column here that has all of the values filled down.
I'm wanting, I want to delete this too and then move this one to the beginning. I'm going to
add and rename this one to "plan" again. All right, now I want to remove like all of the
missing values here because they, I mean they either have totals or they're about rows
that are not part of my data set, my final data sets. I'm just going to remove them. I'm also
going to take a look at mismatched values here, those mismatched values are those that
are not numbers. So I'm going to remove the mismatched values too, and there are
missing values here too that I want to remove.
So this is this is looking much more like the data set that we have here, and we completed
this in only twenty one steps. So this is, this is the final clean data set. So now what you
should do is, if you want to export this to a CSV file you actually select this option here to
"run job". So Dataprep will use its cloud infrastructure to get this recipe that you just
created and then apply it to the data sets that you imported. That's why it's so much more
powerful when you're dealing with massive data sets, but it can also do this with the small
one. You click on "run job", and then you check if everything is ok.
There are options here that you might want to select, for example I want to select that it
will create a CSV file and I have more options here that "include headers as first row on
creation" and then I update this. I'm going to select a location where it's going to save on
my cloud account. I select the regions and then I run the job. And as soon as the job is
done you will get a file a CSV file that is like this, I have it here with me as well. So here is
a CSV file that you might want to load. So this is it for the Dataprep. Go ahead and go to
cloud.google.dataprep and try it out.
