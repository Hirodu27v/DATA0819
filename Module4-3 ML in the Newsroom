ML in the Newsroom
それでは、機械学習を使って対処できるさまざまな問題を、データのタイプ別に見ていきましょう。画像、テキスト、音声などの機械学習に分類できます。
まずは写真の機械学習です。先ほどのセクションで犬と猫の写真を分類してラベルを貼る分類方法を紹介しました。これは非常に便利なツールで、画像分類モデルといいます。
医療業界では広く用いられており、肺のX線画像をみて肺炎か否かを確かめることができます。あらゆる病気や医療スキャンにおいて、機械学習モデルは専門的な訓練を受けた人間の医師よりも正確な判断ができる場合が多いことが分かっています。医療業界ではとても人気があります。
もちろん、データジャーナリズムにも役立ちます。一般に、機械学習は画像に何が含まれているのかを識別することができます。これはルナ・パークという遊園地の写真で、（Google Cloudの）vision APIを使って何が映っているのかを特定しました。
「ランドマーク：96％」というラベルがあります。つまりモデルはこれがランドマークの写真であると96％の確率で判断しているということです。
信仰の場かもしれないとも判断しているようです。これは間違いですが、寺院のように壮大な構造物だと理解している（ためこうした判断が行われた）のです。観光地かもしれません。
これらのラベルはGoogle Cloud のVision APIというツールから取得しました。後でツールのセクションで詳しく説明しますが、これは視覚モデルの一般的なタスクです。
顔を特定することもできます。顔を見つけたら、どんな表情をしているか見てみましょう。このモデルは何の感情も発見できませんでした。帽子があると書いてあります。帽子（のようなもの）があるのは分かりますよね。
さて、誰かが集会を催しているとします。あなたには聴衆の大歓声が聞こえていますが、聴衆の何割が満足し、何割が怒り、何割が悲しんでいるのかを知りたいと考えています。
完璧な機械学習モデルはありません。しかし、感情の検出はごく一般的な課題です。
そして、テキスト抽出であるOCRです。この写真のように標識があります。あるいはPDF、書類、手書きのメモがあるかもしれません。
機械学習を使って、画像からテキストを抽出することができます。
報道機関の編集局ではこれらのツールをどのように使っているのでしょうか？Googleとニューヨークタイムズ紙が共同で行った興味深いプロジェクトがあります。
同紙は写真のデジタル化に長いこと取り組んで来ました。ご覧のように膨大な写真のアーカイブズがあります。写真の裏には編集者、写真記者、記者たちによる、その写真を説明するメモが記されています。
しかし、こうした写真を物理的に整理するのは同紙にとって非常に困難なことでした。どう分類したらいいでしょうか。
彼らはGoogleで写真をスキャンし、vision toolを使って写真に何が映っているのかを特定し、テキストを抽出した上で検索可能なデジタルアーカイブを構築しました。
機械学習はこのように構造化されていない写真のテキストデータを扱いやすいものにするのに非常に役立っています。
また、他にも面白いプロジェクトがあります。顔認識技術を利用してbotをつくり、議員の写真をそれに送ると、誰なのかを教えてくれます。
合衆国下院には非常に多くの議員がいます。とても全員を覚えることはできません。しかし、誰かが通りを歩いていて、それを写真にとるとニューヨークタイムズが議員かどうかを教えてくれます。これが顔認識ツールです。
最後にもう一つ、TEXTYによる興味深いプロジェクトを紹介します。彼らは環境を破壊する違法な琥珀採掘を特定しようと考えました。人々は琥珀を売るために違法な採掘に手を染めます。
彼らは衛星写真を集めましたが、そのうちのどれが違法なものなのか特定できませんでした。そこで、専門家に（いくつか）特定してもらいました。
それから、これらの写真を使って機械学習モデルを訓練し、新しい衛星写真に違法採掘の場面が含まれているのか自動的に分類しようとしたのです。
その結果、インタラクティブな地図を作成し、どれが合法的な採掘か示すことができました。これが画像の機械学習の概要です。
では、音声はどうでしょうか？インタビュー形式のオーディオデータをたくさんお持ちでしょう。コンピュータがインタビューを書き起こしてくれればいいと思いませんか？
これは機械学習とジャーナリズムの交差点です。これまで、報道機関の編集局とは文字起こしの実現を目指して協力してきました。
音声からテキストへの変換を活用して多くの記事が発表されています。何時間にもわたるビデオや音声記録を分析したいとき、そのままのフォーマットではあまり役に立ちません。
データを書き起こしてテキスト形式にすれば素早い分析ができるようになります。フォーブズの記者であるカレブ・リータルーの仕事は多岐にわたります。
彼は文字起こしといくつかのヴィジョンAIツールを使って何週間分ものテレビ映像を分析し、フォーブス誌に記事を書いてきました。これらの記事は参考文献のセクションに置いてあります。
例えばこれは音声ではなく、視覚的（な分析）です。ABC、CBS、NBCなど様々なテレビ局の映像に出てくる全ての顔を、Google社のvision toolを使って特定し、どれだけの人が喜びの表情を浮かべているのかを分析しました。
ABCが一番幸せそうな表情が多く、PBSが一番悲しそうであることが分かりました。彼は同様に、トランプ氏のツイートを表示している局を特定しました。CNNは最も多くツイートを表示し、最も少なく表示したのは当然ながらPBSでした。
映像や音声ファイルの代わりに、分析できるテキストファイルがあればさまざまなことができます。そうそう、テキストデータの機械学習もお話ししましょう。
さっき、犬や猫の写真の分類について話しましたが、テキストのブロックについても同じように分類できます。例えば、テキストが肯定的なことを言及しているのか否定的な内容なのか分類することが可能です。

So we go online, and we scrape all these tweets mentioning different airlines. Jet Green and Ulta. And we label a bunch of them ourselves, and then we can build a machine learning model that automatically identifies positive and negative tweets.
Or maybe we have a bunch of articles that we want to automatically categorize, so we want to sort the electronics articles from the politics articles, from the cooking articles, say.
You can also, of course, do investigative reporting with text classification.

So one of the most impactful and interesting pieces I've seen is from the L.A. Times back in 2014. They wanted to see if they could identify crimes that had been misclassified. So,for example, when a crime occurs, the LAPD classifies it as being a violent crime or not a violent crime, and I guess The L.A. Times wanted to double check. So they collected a bunch of descriptions of crimes, and they had human beings label them as being violent or nonviolent. And they trained a model then that could take a description of a crime and predict: was it a violent or nonviolent crime? Then they looked at thousands of. LAPD's descriptions of crimes, and found that actually a lot of violent crimes involving stabbings, whatever, were being mislabeled as nonviolent. And so in a way, artificially deflating the violent crime rate in L.A. So this awesome peace used machine learning to sort of uncover that.
Now, finally, let's talk about machine learning for tabular data. This is just the sort of data that you would find in a spreadsheet or a database. Numbers, categories, things like this.
So BuzzFeed wrote a piece analyzing tabular data a couple of years ago. It was a really interesting piece, where they wanted to be able to identify hidden spy planes. So they used data from a site called Flight Radar 24, which has all sorts of information on all flights that occur like a flight's altitude, and how long it lasts, and the positions, and stuff like this.
All this information about flights. And BuzzFeed knew that certain flights were spy plane flights and some weren't. And they used this to build a model that, given all of this data about a flight, could predict whether it was a spy plane or not.
What they found was really fascinating. They found, for example, that there were some planes that were supposed to be tracking terrorism in Africa, but there were actually flying over U.S. cities. And they found, for example, planes that were tracking drug cartels on the border. And lots of things that work were sort of unexplained to them when they wrote the piece. They were able to to learn more about them.
So the model would say this is a spy plane, and then the reporters would try to verify.
However, the model made mistakes a lot. For example, it consistently recognized skydiving planes as spy planes because they also have these weird, loopy trajectories. So there's a great lesson to be learned here, which is that all machine learning models make errors, and sometimes they make them consistently, like consistently misclassifying skydiving planes.
So it's important when you're a reporter to understand how to work with these models, and when they make predictions that say something damning like this is a secret spy plane, that you as the reporter have to go and then verify that plane using traditional reporting.
