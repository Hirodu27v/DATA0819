ML in the Newsroom
それでは、機械学習を使って対処できるさまざまな問題を、データのタイプ別に見ていきましょう。画像、テキスト、音声などの機械学習に分類できます。
まずは写真の機械学習です。先ほどのセクションで犬と猫の写真を分類してラベルを貼る分類方法を紹介しました。これは非常に便利なツールで、画像分類モデルといいます。
医療業界では広く用いられており、肺のX線画像をみて肺炎か否かを確かめることができます。あらゆる病気や医療スキャンにおいて、機械学習モデルは専門的な訓練を受けた人間の医師よりも正確な判断ができる場合が多いことが分かっています。医療業界ではとても人気があります。
もちろん、データジャーナリズムにも役立ちます。一般に、機械学習は画像に何が含まれているのかを識別することができます。これはルナ・パークという遊園地の写真で、（Google Cloudの）vision APIを使って何が映っているのかを特定しました。
「ランドマーク：96％」というラベルがあります。つまりモデルはこれがランドマークの写真であると96％の確率で判断しているということです。
信仰の場かもしれないとも判断しているようです。これは間違いですが、寺院のように壮大な構造物だと理解している（ためこうした判断が行われた）のです。観光地かもしれません。
これらのラベルはGoogle Cloud のVision APIというツールから取得しました。後でツールのセクションで詳しく説明しますが、これは視覚モデルの一般的なタスクです。
顔を特定することもできます。顔を見つけたら、どんな表情をしているか見てみましょう。このモデルは何の感情も発見できませんでした。帽子があると書いてあります。帽子（のようなもの）があるのは分かりますよね。
さて、誰かが集会を催しているとします。あなたには聴衆の大歓声が聞こえていますが、聴衆の何割が満足し、何割が怒り、何割が悲しんでいるのかを知りたいと考えています。
完璧な機械学習モデルはありません。しかし、感情の検出はごく一般的な課題です。
そして、テキスト抽出であるOCRです。この写真のように標識があります。あるいはPDF、書類、手書きのメモがあるかもしれません。
機械学習を使って、画像からテキストを抽出することができます。
報道機関の編集局ではこれらのツールをどのように使っているのでしょうか？Googleとニューヨークタイムズ紙が共同で行った興味深いプロジェクトがあります。
同紙は写真のデジタル化に長いこと取り組んで来ました。ご覧のように膨大な写真のアーカイブズがあります。写真の裏には編集者、写真記者、記者たちによる、その写真を説明するメモが記されています。
しかし、こうした写真を物理的に整理するのは同紙にとって非常に困難なことでした。どう分類したらいいでしょうか。
彼らはGoogleで写真をスキャンし、vision toolを使って写真に何が映っているのかを特定し、テキストを抽出した上で検索可能なデジタルアーカイブを構築しました。
機械学習はこのように構造化されていない写真のテキストデータを扱いやすいものにするのに非常に役立っています。
また、他にも面白いプロジェクトがあります。顔認識技術を利用してbotをつくり、議員の写真をそれに送ると、誰なのかを教えてくれます。
合衆国下院には非常に多くの議員がいます。とても全員を覚えることはできません。しかし、誰かが通りを歩いていて、それを写真にとるとニューヨークタイムズが議員かどうかを教えてくれます。これが顔認識ツールです。
最後にもう一つ、TEXTYによる興味深いプロジェクトを紹介します。彼らは環境を破壊する違法な琥珀採掘を特定しようと考えました。人々は琥珀を売るために違法な採掘に手を染めます。
彼らは衛星写真を集めましたが、そのうちのどれが違法なものなのか特定できませんでした。そこで、専門家に（いくつか）特定してもらいました。
それから、これらの写真を使って機械学習モデルを訓練し、新しい衛星写真に違法採掘の場面が含まれているのか自動的に分類しようとしたのです。
その結果、インタラクティブな地図を作成し、どれが合法的な採掘か示すことができました。これが画像の機械学習の概要です。
では、音声はどうでしょうか？インタビュー形式のオーディオデータをたくさんお持ちでしょう。コンピュータがインタビューを書き起こしてくれればいいと思いませんか？
これは機械学習とジャーナリズムの交差点です。これまで、報道機関の編集局とは文字起こしの実現を目指して協力してきました。
音声からテキストへの変換を活用して多くの記事が発表されています。何時間にもわたるビデオや音声記録を分析したいとき、そのままのフォーマットではあまり役に立ちません。
データを書き起こしてテキスト形式にすれば素早い分析ができるようになります。フォーブズの記者であるカレブ・リータルーの仕事は多岐にわたります。
彼は文字起こしといくつかのヴィジョンAIツールを使って何週間分ものテレビ映像を分析し、フォーブス誌に記事を書いてきました。これらの記事は参考文献のセクションに置いてあります。
例えばこれは音声ではなく、視覚的（な分析）です。ABC、CBS、NBCなど様々なテレビ局の映像に出てくる全ての顔を、Google社のvision toolを使って特定し、どれだけの人が喜びの表情を浮かべているのかを分析しました。
ABCが一番幸せそうな表情が多く、PBSが一番悲しそうであることが分かりました。彼は同様に、トランプ氏のツイートを表示している局を特定しました。CNNは最も多くツイートを表示し、最も少なく表示したのは当然ながらPBSでした。
映像や音声ファイルの代わりに、分析できるテキストファイルがあればさまざまなことができます。そうそう、テキストデータの機械学習もお話ししましょう。
さっき、犬や猫の写真の分類について話しましたが、テキストのブロックについても同じように分類できます。
例えば、テキストが肯定的なことを言及しているのか否定的な内容なのか分類することが可能です。どの航空会社が一番いいでしょう。オンラインでさまざまな航空会社に関するツイートを集めてきました。
（架空の会社である）ジェットグリーンとアルタです。まず自分でラベルを付け、肯定的なつぶやきと否定的なものを自動的に識別する機械学習モデルを構築することが出来ます。
あるいは、たくさんの電子版の記事を政治や料理といったように分類することもできます。もちろんこのテキスト分類を利用して調査報道をすることも可能です。
私が知る限り最も衝撃的な記事の一つはＬＡタイムズの2014年の記事です。ロサンゼルス市警は事件を暴力犯罪とその他の犯罪に分けており、ＬＡタイムズはこれを検証しました。
犯行事例を集め、人間に暴力犯罪か、非暴力的な犯罪化のラベルを付けた上で暴力犯罪を識別するようにモデルを訓練しました。数千件を分類したところ、市警は刺傷を含む多くの犯罪が非暴力的と誤認されていたのです。
つまり、ロサンゼルスの暴力犯罪率は人為的に抑制されたものだったのです。機械学習はこの驚くべき「平和」の実態を暴いたのでした。
最後に、表形式データの機械学習について説明します。これはスプレッドシートやデータベースにあるようなデータです。
BuzzFeedは数年前、表形式のデータを分析する記事を書きました。実に興味深い作品で、彼らは秘匿された偵察機の識別を試みました。Flight Radar24という飛行機の高度や飛行時間、位置を記録したサイトのデータを利用しました。
BuzzFeedによれば、この中には偵察機もあれば、それ以外のものもあります。彼らはこれを元に、それが偵察機かどうか予測するモデルを作りました。
結果はとても興味深いものでした。アフリカでテロを追跡しているはずの飛行機は実際にはアメリカの都市の上空を飛んでいました。
また、国境地帯で麻薬カルテルを追跡している機もありました。当時、明らかにされていなかった多くのことをつかんだのです。
モデルはこれを偵察機だと判断し、記者はそれを検証しました。しかし、このモデルは多くのミスを犯しました。スカイダイビングの飛行機はループ状の航跡を残していたので、全て偵察機と認識されていました。
これは、あらゆる機械学習モデルはミスを排除できないという素晴らしい教訓を残しました。スカイダイビングの飛行機と同じようなミスをする可能性は常にあります。
したがって、記者はモデルの扱い方を理解しておくことが重要です。モデルが秘密の偵察機だと判断したら、記者として昔ながらの方法にのっとりその機を検証する必要があるのです。
