ML in the Newsroom
それでは、機械学習を使って対処できるさまざまな問題を、データのタイプ別に見ていきましょう。画像、テキスト、音声などの機械学習に分類できます。
まずは写真の機械学習です。先ほどのセクションで犬と猫の写真を分類してラベルを貼る分類方法を紹介しました。これは非常に便利なツールで、画像分類モデルといいます。
医療業界では広く用いられており、肺のX線画像をみて肺炎か否かを確かめることができます。あらゆる病気や医療スキャンにおいて、機械学習モデルは専門的な訓練を受けた人間の医師よりも正確な判断ができる場合が多いことが分かっています。医療業界ではとても人気があります。
もちろん、データジャーナリズムにも役立ちます。一般に、機械学習は画像に何が含まれているのかを識別することができます。これはルナ・パークという遊園地の写真で、（Google Cloudの）vision APIを使って何が映っているのかを特定しました。
「ランドマーク：96％」というラベルがあります。つまりモデルはこれがランドマークの写真であると96％の確率で判断しているということです。
信仰の場かもしれないとも判断しているようです。これは間違いですが、寺院のように壮大な構造物だと理解している（ためこうした判断が行われた）のです。観光地かもしれません。
これらのラベルはGoogle Cloud のVision APIというツールから取得しました。後でツールのセクションで詳しく説明しますが、これは視覚モデルの一般的なタスクです。
顔を特定することもできます。顔を見つけたら、どんな表情をしているか見てみましょう。このモデルは何の感情も発見できませんでした。帽子があると書いてあります。帽子（のようなもの）があるのは分かりますよね。
さて、誰かが集会を催しているとします。あなたには聴衆の大歓声が聞こえていますが、聴衆の何割が満足し、何割が怒り、何割が悲しんでいるのかを知りたいと考えています。
完璧な機械学習モデルはありません。しかし、感情の検出はごく一般的な課題です。
そして、テキスト抽出であるOCRです。この写真のように標識があります。あるいはPDF、書類、手書きのメモがあるかもしれません。
機械学習を使って、画像からテキストを抽出することができます。
報道機関の編集局ではこれらのツールをどのように使っているのでしょうか？Googleとニューヨークタイムズ紙が共同で行った興味深いプロジェクトがあります。
同紙は写真のデジタル化に長いこと取り組んで来ました。
So they had this enormous archive of physical pictures, as you can see, here. And on the back of these pictures would be all these sorts of notes from editors, and the photographer, and the reporter, explaining where the photos should go and what it is about. But it was very hard for New York Times to deal with all these photos because they were all physical. How are you going to sort through them?
So with Google, they scanned their photos and then used our vision tools to identify, for example, what was in the pictures, in order to extract the text, and then to ultimately make this sort of searchable digital archive. So machine learning is really very good for organizing this sort of unstructured photo text data into something that's more manageable.
The New York Times also worked on this sort of other fun project. They used facial recognition to build a bot where you could text a picture of a member of Congress, and it would tell you who it thought the person was and with what confidence. So the idea is that there are so many members of the House of Representatives. How are you gonna  remember them all? Well, if you see someone you think you might recognize walking down the street, you take a picture, and The New York Times tells you if it thinks its a member of Congress. This is a facial recognition tool.
And finally, another interesting project that used machine-learning provision was a piece by a Texty. So they wanted to identify illegal amber mining, which was destroying environments. People illegally mining in order to sell. So they collected all of these satellite pictures of different regions, where they knew contained and didn't contain illegal amber mines. And they used experts to identify which ones were the illegal mines and so forth.

And they used all these pictures to train a machine-learning model to look at new satellite images and to try to automatically classify whether the site contained illegal mining. And as a result, they were able to make this interactive map, where they could point out where they thought all legal mining was occurring.
So that's an overview of machine learning with images. What about machine learning for audio data? You probably have a lot of audio data in the form of interviews. And wouldn't it be nice if a computer could come along and transcribe your interviews for you? That's certainly a great intersection of machine learning and journalism. I think it's something that we've worked with newsrooms to try to make happen. To try to help with the entry transcription.
But you can also use speech-to-text transcription for lots of investigative reporting. So, for example, if you have hours and hours of videos or voice footage and you want to analyze it, well, it's not really useful in those formats. Wouldn't it be so much faster if you could have that data in text format like transcriptions?
So, for example, there's a lot of work done by Kalev Leetaru. He's a reporter that's published a lot in Forbes. And he's used transcription and different vision AI tools to analyze television, weeks and weeks of television, and wrote a bunch of pieces for Forbes on it. I've included them in the extended reading section.
So, for example, this isn't audio. This is vision. But he looked at film from all these different news stations ABC, CBS, NBC, and so on. And he identified all the faces using our vision tool and tried to calculate how many were expressing joy. He found that ABC was the happiest, and PBS was the saddest. He also used this to identify what a new station was showing a Trump tweet. It was able to tell that CNN showed the most Trump tweets, and PBS unsurprisingly showed the fewest Trump tweets.
So, again, a lot of different things that you can do when instead of having a video or audio file, you instead have text that you can analyze. Speaking of text that you can analyze, let's talk about machine learning for text data.
Before we talked about classifying photos of cats or dogs, but of course we could also classify blocks of text. So, for example, sentiment classification. That's whether a text is saying something positive or negative. Maybe we want to know what's the best airline. So we go online, and we scrape all these tweets mentioning different airlines. Jet Green and Ulta. And we label a bunch of them ourselves, and then we can build a machine learning model that automatically identifies positive and negative tweets.
Or maybe we have a bunch of articles that we want to automatically categorize, so we want to sort the electronics articles from the politics articles, from the cooking articles, say.
You can also, of course, do investigative reporting with text classification.
So one of the most impactful and interesting pieces I've seen is from the L.A. Times back in 2014. They wanted to see if they could identify crimes that had been misclassified. So,for example, when a crime occurs, the LAPD classifies it as being a violent crime or not a violent crime, and I guess The L.A. Times wanted to double check. So they collected a bunch of descriptions of crimes, and they had human beings label them as being violent or nonviolent. And they trained a model then that could take a description of a crime and predict: was it a violent or nonviolent crime? Then they looked at thousands of. LAPD's descriptions of crimes, and found that actually a lot of violent crimes involving stabbings, whatever, were being mislabeled as nonviolent. And so in a way, artificially deflating the violent crime rate in L.A. So this awesome peace used machine learning to sort of uncover that.
Now, finally, let's talk about machine learning for tabular data. This is just the sort of data that you would find in a spreadsheet or a database. Numbers, categories, things like this.
So BuzzFeed wrote a piece analyzing tabular data a couple of years ago. It was a really interesting piece, where they wanted to be able to identify hidden spy planes. So they used data from a site called Flight Radar 24, which has all sorts of information on all flights that occur like a flight's altitude, and how long it lasts, and the positions, and stuff like this.
All this information about flights. And BuzzFeed knew that certain flights were spy plane flights and some weren't. And they used this to build a model that, given all of this data about a flight, could predict whether it was a spy plane or not.
What they found was really fascinating. They found, for example, that there were some planes that were supposed to be tracking terrorism in Africa, but there were actually flying over U.S. cities. And they found, for example, planes that were tracking drug cartels on the border. And lots of things that work were sort of unexplained to them when they wrote the piece. They were able to to learn more about them.
So the model would say this is a spy plane, and then the reporters would try to verify.
However, the model made mistakes a lot. For example, it consistently recognized skydiving planes as spy planes because they also have these weird, loopy trajectories. So there's a great lesson to be learned here, which is that all machine learning models make errors, and sometimes they make them consistently, like consistently misclassifying skydiving planes.
So it's important when you're a reporter to understand how to work with these models, and when they make predictions that say something damning like this is a secret spy plane, that you as the reporter have to go and then verify that plane using traditional reporting.
